# CNN Classification
##  <font color="#8450B2">_Group: 3PM ğŸ‘§ğŸ»ğŸ‘©ğŸ»ğŸ‘©ğŸ¼ğŸ‘¦ğŸ»_</font> <br>


## _ğŸ’«Key HighlightğŸ’«_

## ğŸ“–Contents
[Code.ipynp]()
 - [1. IntroductionğŸ†ğŸ…](https://github.com/Mayypeeya/CNN_Classification#1-introduction)
 - [2. DatasetğŸ”](https://github.com/Mayypeeya/CNN_Classification#2-data%EF%B8%8F)
 - [3. Network architectureğŸŒ](https://github.com/Mayypeeya/CNN_Classification#3-network-architecture)
 - [4. TrainingğŸ‘»](https://github.com/Mayypeeya/CNN_Classification#4-training)
 - [5. ResultsğŸ“ˆ](https://github.com/Mayypeeya/CNN_Classification#5-results)
 - [6. DiscussionğŸ’­](https://github.com/Mayypeeya/CNN_Classification#6discussion)
 - [7. ConclusionğŸ‘‘](https://github.com/Mayypeeya/CNN_Classification#7-conclusion)
 - [8. ReferencesâœğŸ¼](https://github.com/Mayypeeya/CNN_Classification#8-references)


## 1. IntroductionğŸ†ğŸ…
Transfer Learning is about pre-trained model usage or weights of models that were trained with another huge dataset to be used with an interesting dataset. This helps to reduce the process and time for training the model manually and also improves the efficiency of the model's learning.
<br>Our group used weight from a pre-trained of CNN model that was trained by ImageNet Dataset. And used it with multi-class classification. The eggplant 3 types and tomato were classified as having individual characteristics along with this dataset has never been trained before. The classes of different data that be used have different characteristics as follows:

![image](https://user-images.githubusercontent.com/101736826/197330900-847b5260-5ccc-479c-93ac-8d12f763eda0.png)


## 2. DatasetğŸ–¼ï¸
- We have compiled images by searching on the internet total of 4 types which total 600 images. See details in each class in the table.
#### ğŸ”Data collection (Internet Seaching) 
[ğŸ”—Link to download the dataset:](https://github.com/Mayypeeya/CNN_Classification/tree/main/01_DataSet_image)
<img width="523" alt="image" src="https://user-images.githubusercontent.com/69892468/197325994-e3aa997e-634f-4615-92fe-96e2a92702eb.png">

<img width="635" alt="image" src="https://user-images.githubusercontent.com/69892468/197326053-fa8b8df7-bacb-4e64-ad59-8ba1eaf65c49.png">

#### ğŸ“‘Data preparation
In the process, all images were converted to .jpg files and manually extracted into sub-folders for easy access in the next steps.
1. **Transform the image dataset** to NUMPY array in 3 channels by using "cv2.imread"
2. **Resize the image dataset** to 224x224 pixels
3. **Split Dataset** by mannual selection at 30% for testing set.
- **`test_size`** = 0.3
- **`Train Data`**: 105 images
- **`Test Data`**: 45 images
4. **Data Augmentation** filp images in Herizontal and Vertical
```
train_datagenerate = tf.keras.preprocessing.image.ImageDataGenerator(
                                samplewise_center=True,
                                samplewise_std_normalization=True,
                                horizontal_flip=**True**,
                                vertical_flip=**True**,
                                validation_split=0.2) 
train_datagenerate.fit(x_train)
````



<img width="641" alt="image" src="https://user-images.githubusercontent.com/69892468/197327680-d17e2514-ea09-4e6d-a002-75554b2d2539.png">
<img width="635" alt="image" src="https://user-images.githubusercontent.com/69892468/197327699-0db3a12a-e520-4c93-aaa6-14a2d43e07a3.png">

## 3. Network architectureğŸŒ

### 3.1 Transfer learning
<img width="452" alt="image" src="https://user-images.githubusercontent.com/69892468/197329795-06d98ea5-affd-4234-a9ad-cb1d14b624f3.png">




### 3.2 No Fine-tuning
<img width="393" alt="image" src="https://user-images.githubusercontent.com/69892468/197326003-86613aa4-271f-4b58-bcef-c24430e9148b.png">

### 3.3 Fine-tuning







## 4. TrainingğŸ‘»



## 5. ResultsğŸ“ˆ


  

## 6.DiscussionğŸ’­


## 7. ConclusionğŸ‘‘



## 8. ReferencesâœğŸ¼

 
## _End Credit_


_à¸‡à¸²à¸™à¸Šà¸´à¹‰à¸™à¸™à¸µà¹‰à¹€à¸›à¹‡à¸™à¸ªà¹ˆà¸§à¸™à¸«à¸™à¸¶à¹ˆà¸‡à¸‚à¸­à¸‡ à¸§à¸´à¸Šà¸²à¸à¸²à¸£à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¹€à¸Šà¸´à¸‡à¸à¸³à¸«à¸™à¸”à¹à¸¥à¸°à¸à¸²à¸£à¸«à¸²à¸„à¹ˆà¸²à¹€à¸«à¸¡à¸²à¸°à¸ªà¸¸à¸”à¸›à¸£à¸°à¸¢à¸¸à¸à¸•à¹Œ à¸«à¸¥à¸±à¸à¸ªà¸¹à¸•à¸£à¸§à¸´à¸—à¸¢à¸²à¸¨à¸²à¸ªà¸•à¸£à¸¡à¸«à¸²à¸šà¸±à¸“à¸‘à¸´à¸• à¸ªà¸²à¸‚à¸²à¸§à¸´à¸Šà¸²à¸à¸²à¸£à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹à¸¥à¸°à¸§à¸´à¸—à¸¢à¸²à¸à¸²à¸£à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ à¸¡à¸«à¸²à¸§à¸´à¸—à¸¢à¸²à¸¥à¸±à¸¢à¸ªà¸–à¸²à¸šà¸±à¸™à¸šà¸±à¸“à¸‘à¸´à¸•à¸à¸±à¸’à¸™à¸šà¸£à¸´à¸«à¸²à¸£à¸¨à¸²à¸ªà¸•à¸£à¹Œ_
